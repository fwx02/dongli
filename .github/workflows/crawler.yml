name: 书籍爬虫

on:
  schedule:
    - cron: '0 11 * * *'  # 每天UTC时间4点（北京时间12点）运行
  workflow_dispatch:  # 允许手动触发

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: 检出代码
        uses: actions/checkout@v4
      
      - name: 设置Python环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
      
      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4
      
      - name: 下载数据库文件（如果存在）
        uses: actions/download-artifact@v4
        with:
          name: database
          path: .
        continue-on-error: true  # 允许下载失败并继续执行
      
      - name: 检查数据库文件是否存在
        id: check-db
        run: |
          if [ -f "book_history.db" ]; then
            echo "db_exists=true" >> $GITHUB_OUTPUT
            echo "数据库文件存在，将使用现有数据"
          else
            echo "db_exists=false" >> $GITHUB_OUTPUT
            echo "数据库文件不存在，将创建新数据库"
          fi
      
      - name: 运行爬虫
        env:
          WECHAT_WORK_WEBHOOK: ${{ secrets.WECHAT_WORK_WEBHOOK }}
          DB_DIR: .
        run: |
          python crawler.py
      
      - name: 上传数据库文件
        uses: actions/upload-artifact@v4
        with:
          name: database
          path: book_history.db
          retention-days: 30  # 保留30天，方便查看历史数据
      
      - name: 上传日志文件
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: crawler.log
