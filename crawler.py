import requests
from bs4 import BeautifulSoup
import json
import logging
import time
import datetime
import os
import sqlite3

# ä»ç¯å¢ƒå˜é‡è·å–ä¼ä¸šå¾®ä¿¡Webhook
WECHAT_WORK_WEBHOOK = os.getenv("WECHAT_WORK_WEBHOOK")
DB_FILE = "book_history.db"  # å­˜å‚¨å†å²æ•°æ®çš„SQLiteæ•°æ®åº“æ–‡ä»¶
MAX_MESSAGES_PER_DAY = 3  # æ¯æ—¥æœ€å¤šå‘é€çš„æ¶ˆæ¯æ•°
MIN_INTERVAL_BETWEEN_MESSAGES = 60  # æ¶ˆæ¯ä¹‹é—´çš„æœ€å°é—´éš”ï¼ˆç§’ï¼‰
LAST_MESSAGE_TIME_FILE = "last_message_time.txt"  # è®°å½•ä¸Šæ¬¡å‘é€æ¶ˆæ¯çš„æ—¶é—´
MAX_MESSAGE_LENGTH = 3600  # æ›´ä¿å®ˆçš„æ¶ˆæ¯æœ€å¤§é•¿åº¦é™åˆ¶ï¼ˆç•™å‡º496å­—èŠ‚å®‰å…¨ä½™é‡ï¼‰
MAX_BOOKS_PER_SECTION = 20  # æ¯ä¸ªåˆ†æ®µæœ€å¤šåŒ…å«çš„ä¹¦ç±æ•°é‡ï¼ˆè¿›ä¸€æ­¥é™ä½ï¼‰

def create_database():
    """åˆ›å»ºæ•°æ®åº“è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS books (
                title TEXT PRIMARY KEY,
                publish_month TEXT,
                first_seen TEXT,
                last_seen TEXT,
                is_published INTEGER DEFAULT 0
            )
        ''')
        conn.commit()
        conn.close()
        logging.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logging.error(f"åˆ›å»ºæ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")

def check_book_exists(title):
    """æ£€æŸ¥ä¹¦ç±æ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼ˆæ— è®ºæ˜¯å¦å·²å‡ºç‰ˆï¼‰"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM books WHERE title = ?", (title,))
        result = cursor.fetchone()
        conn.close()
        return result is not None
    except Exception as e:
        logging.error(f"æ£€æŸ¥ä¹¦ç±æ—¶å‡ºé”™: {str(e)}")
        return False

def add_book(title, publish_month, first_seen, last_seen):
    """å°†æ–°ä¹¦æ·»åŠ åˆ°æ•°æ®åº“"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute(
            """INSERT INTO books (title, publish_month, first_seen, last_seen, is_published) 
               VALUES (?, ?, ?, ?, 0)""",
            (title, publish_month, first_seen, last_seen)
        )
        conn.commit()
        conn.close()
        logging.info(f"æ–°ä¹¦å·²æ·»åŠ åˆ°æ•°æ®åº“: {title}")
        return True
    except sqlite3.IntegrityError:
        # ä¹¦ç±å·²å­˜åœ¨ï¼Œæ›´æ–°last_seenï¼ˆä»…å½“ä¹¦ç±æœªè¢«æ ‡è®°ä¸ºå·²å‡ºç‰ˆæ—¶ï¼‰
        update_book_last_seen(title, last_seen)
        return False
    except Exception as e:
        logging.error(f"æ·»åŠ ä¹¦ç±æ—¶å‡ºé”™: {str(e)}")
        return False

def update_book_last_seen(title, last_seen):
    """æ›´æ–°ä¹¦ç±çš„æœ€åä¸€æ¬¡å‡ºç°æ—¶é—´ï¼ˆä»…å½“ä¹¦ç±æœªè¢«æ ‡è®°ä¸ºå·²å‡ºç‰ˆæ—¶ï¼‰"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        # åªæ›´æ–°æœªå‡ºç‰ˆçš„ä¹¦ç±
        cursor.execute(
            "UPDATE books SET last_seen = ? WHERE title = ? AND is_published = 0",
            (last_seen, title)
        )
        conn.commit()
        conn.close()
    except Exception as e:
        logging.error(f"æ›´æ–°ä¹¦ç±last_seenæ—¶å‡ºé”™: {str(e)}")

def mark_book_as_published(title, publish_date=None):
    """æ ‡è®°ä¹¦ç±ä¸ºå·²å‡ºä¹¦"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        # å¦‚æœæä¾›äº†å‡ºç‰ˆæ—¥æœŸï¼Œæ›´æ–°publish_month
        if publish_date:
            cursor.execute(
                "UPDATE books SET is_published = 1, publish_month = ? WHERE title = ?",
                (publish_date, title)
            )
        else:
            cursor.execute(
                "UPDATE books SET is_published = 1 WHERE title = ?",
                (title,)
            )
        conn.commit()
        conn.close()
        logging.info(f"ä¹¦ç±å·²æ ‡è®°ä¸ºå·²å‡ºä¹¦: {title}")
        return True
    except Exception as e:
        logging.error(f"æ ‡è®°ä¹¦ç±ä¸ºå·²å‡ºä¹¦æ—¶å‡ºé”™: {str(e)}")
        return False

def get_unpublished_books():
    """è·å–æ‰€æœ‰æœªå‡ºä¹¦çš„ä¹¦ç±"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute("SELECT title, publish_month, first_seen, last_seen FROM books WHERE is_published = 0")
        result = cursor.fetchall()
        conn.close()
        return [
            {
                "title": row[0],
                "publish_month": row[1],
                "first_seen": row[2],
                "last_seen": row[3]
            }
            for row in result
        ]
    except Exception as e:
        logging.error(f"è·å–æœªå‡ºä¹¦ä¹¦ç±æ—¶å‡ºé”™: {str(e)}")
        return []

def check_and_mark_published_books(current_books):
    """æ£€æŸ¥å¹¶æ ‡è®°å·²å‡ºä¹¦çš„ä¹¦ç±"""
    try:
        current_titles = [book["title"] for book in current_books]
        unpublished_books = get_unpublished_books()
        
        published_books = []
        for book in unpublished_books:
            if book["title"] not in current_titles:
                if mark_book_as_published(book["title"]):
                    published_books.append(book)
        
        return published_books
    except Exception as e:
        logging.error(f"æ£€æŸ¥å¹¶æ ‡è®°å·²å‡ºä¹¦ä¹¦ç±æ—¶å‡ºé”™: {str(e)}")
        return []

def get_last_message_time():
    """è·å–ä¸Šæ¬¡å‘é€æ¶ˆæ¯çš„æ—¶é—´"""
    try:
        if os.path.exists(LAST_MESSAGE_TIME_FILE):
            with open(LAST_MESSAGE_TIME_FILE, 'r') as f:
                timestamp = float(f.read().strip())
                return datetime.datetime.fromtimestamp(timestamp)
        return None
    except Exception as e:
        logging.error(f"è¯»å–ä¸Šæ¬¡å‘é€æ¶ˆæ¯æ—¶é—´æ—¶å‡ºé”™: {str(e)}")
        return None

def save_last_message_time():
    """ä¿å­˜å½“å‰æ—¶é—´ä¸ºä¸Šæ¬¡å‘é€æ¶ˆæ¯çš„æ—¶é—´"""
    try:
        with open(LAST_MESSAGE_TIME_FILE, 'w') as f:
            f.write(str(time.time()))
    except Exception as e:
        logging.error(f"ä¿å­˜ä¸Šæ¬¡å‘é€æ¶ˆæ¯æ—¶é—´æ—¶å‡ºé”™: {str(e)}")

def send_combined_message(title, content):
    """å‘é€åˆå¹¶åçš„ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ï¼ˆè€ƒè™‘APIé™åˆ¶ï¼‰"""
    if not WECHAT_WORK_WEBHOOK:
        logging.warning("æœªè®¾ç½®ä¼ä¸šå¾®ä¿¡Webhookï¼Œæ— æ³•å‘é€é€šçŸ¥")
        return False
    
    # æ£€æŸ¥ä¸Šæ¬¡å‘é€æ—¶é—´ï¼Œç¡®ä¿ç¬¦åˆæœ€å°é—´éš”è¦æ±‚
    last_time = get_last_message_time()
    now = datetime.datetime.now()
    
    if last_time and (now - last_time).total_seconds() < MIN_INTERVAL_BETWEEN_MESSAGES:
        wait_time = MIN_INTERVAL_BETWEEN_MESSAGES - (now - last_time).total_seconds()
        logging.info(f"è·ç¦»ä¸Šæ¬¡å‘é€æ¶ˆæ¯æ—¶é—´ä¸è¶³ï¼Œç­‰å¾… {wait_time:.0f} ç§’")
        time.sleep(wait_time)
    
    # æ„å»ºå®Œæ•´çš„è¯·æ±‚JSONå¹¶è®¡ç®—å…¶å­—èŠ‚é•¿åº¦
    data = {
        "msgtype": "markdown",
        "markdown": {
            "content": content
        }
    }
    json_data = json.dumps(data, ensure_ascii=False).encode('utf-8')
    json_length = len(json_data)
    
    # æ£€æŸ¥JSONåºåˆ—åŒ–åçš„æ€»é•¿åº¦
    if json_length > 4096:
        logging.warning(f"å®Œæ•´JSONè¯·æ±‚é•¿åº¦ {json_length} è¶…è¿‡ä¼ä¸šå¾®ä¿¡é™åˆ¶ 4096 å­—èŠ‚")
        
        # ä¼°ç®—å†…å®¹éƒ¨åˆ†å¯ä»¥å®¹çº³çš„é•¿åº¦
        estimated_content_length = 4096 - (json_length - len(content.encode('utf-8'))) - 100
        if estimated_content_length < 1000:  # è®¾ç½®ä¸€ä¸ªåˆç†çš„æœ€å°å€¼
            estimated_content_length = 1000
        
        logging.info(f"ä¼°ç®—å†…å®¹æœ€å¤§é•¿åº¦ä¸º {estimated_content_length} å­—èŠ‚")
        
        # æˆªæ–­å†…å®¹å¹¶æ·»åŠ æç¤º
        truncated_content = content.encode('utf-8')[:estimated_content_length].decode('utf-8', 'ignore')
        truncated_content = truncated_content.rsplit('\n', 1)[0]  # ç¡®ä¿åœ¨å®Œæ•´çš„ä¸€è¡Œç»“æŸ
        truncated_content += "\n\n...ï¼ˆå†…å®¹è¿‡é•¿ï¼Œå·²è‡ªåŠ¨æˆªæ–­ï¼‰"
        
        # é‡æ–°æ„å»ºå¹¶æ£€æŸ¥
        data["markdown"]["content"] = truncated_content
        json_data = json.dumps(data, ensure_ascii=False).encode('utf-8')
        logging.info(f"æˆªæ–­åJSONè¯·æ±‚é•¿åº¦ä¸º {len(json_data)} å­—èŠ‚")
    
    try:
        # é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(WECHAT_WORK_WEBHOOK, headers={'Content-Type': 'application/json'}, 
                                        data=json_data, timeout=15)
                response.raise_for_status()
                
                result = response.json()
                if result.get("errcode") == 0:
                    logging.info(f"ä¼ä¸šå¾®ä¿¡é€šçŸ¥å‘é€æˆåŠŸ: {title}ï¼Œé•¿åº¦ {len(json_data)} å­—èŠ‚")
                    save_last_message_time()  # ä¿å­˜å‘é€æ—¶é—´
                    return True
                else:
                    logging.error(f"ä¼ä¸šå¾®ä¿¡APIè¿”å›é”™è¯¯: {result}")
                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                        logging.info(f"å°è¯•é‡è¯• ({attempt+1}/{max_retries})ï¼Œç­‰å¾… {wait_time} ç§’")
                        time.sleep(wait_time)
                    else:
                        return False
            except requests.exceptions.RequestException as e:
                logging.error(f"å‘é€è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    logging.info(f"å°è¯•é‡è¯• ({attempt+1}/{max_retries})ï¼Œç­‰å¾… {wait_time} ç§’")
                    time.sleep(wait_time)
                else:
                    return False
            
        return False
    except Exception as e:
        logging.error(f"å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥æ—¶å‡ºé”™: {str(e)}")
        return False

def send_wechat_notification(title, content):
    """å‘é€ä¼ä¸šå¾®ä¿¡æœºå™¨äººé€šçŸ¥ï¼ˆåˆå¹¶æ‰€æœ‰å†…å®¹ï¼Œè€ƒè™‘APIé™åˆ¶ï¼‰"""
    # æ™ºèƒ½åˆ†æ®µç®—æ³• - åŸºäºJSONåºåˆ—åŒ–åçš„å®é™…é•¿åº¦æ§åˆ¶
    sections = []
    current_section = ""
    
    # æŒ‰æœˆä»½åˆ†å‰²å†…å®¹
    month_sections = content.split("\n\n## ")
    
    for i, section in enumerate(month_sections):
        if i == 0:  # ç¬¬ä¸€ä¸ªéƒ¨åˆ†ï¼ˆæ ‡é¢˜å’Œå¼•è¨€ï¼‰
            current_section = section
        else:
            section_content = "## " + section
            
            # è®¡ç®—æ·»åŠ æ–°éƒ¨åˆ†åçš„å®Œæ•´JSONé•¿åº¦
            test_data = {
                "msgtype": "markdown",
                "markdown": {
                    "content": current_section + "\n\n" + section_content
                }
            }
            test_length = len(json.dumps(test_data, ensure_ascii=False).encode('utf-8'))
            
            # å¦‚æœæ·»åŠ å½“å‰éƒ¨åˆ†ä¼šè¶…è¿‡æœ€å¤§é•¿åº¦é™åˆ¶
            if test_length > 4096:
                # ä¿å­˜å½“å‰éƒ¨åˆ†å¹¶å¼€å§‹æ–°çš„éƒ¨åˆ†
                sections.append(current_section)
                current_section = section_content
            else:
                # ç»§ç»­æ·»åŠ åˆ°å½“å‰éƒ¨åˆ†
                current_section += "\n\n" + section_content
    
    # æ·»åŠ æœ€åä¸€ä¸ªéƒ¨åˆ†
    if current_section:
        sections.append(current_section)
    
    # å‘é€æ‰€æœ‰éƒ¨åˆ†
    success = True
    for i, section in enumerate(sections):
        if i == 0:
            section_title = title
        else:
            section_title = f"{title} (ç»­{i})"
        
        # è®°å½•æ¯ä¸ªåˆ†æ®µçš„JSONé•¿åº¦
        section_data = {
            "msgtype": "markdown",
            "markdown": {
                "content": section
            }
        }
        section_length = len(json.dumps(section_data, ensure_ascii=False).encode('utf-8'))
        logging.info(f"å‘é€åˆ†æ®µ {i+1}/{len(sections)}: {section_title}ï¼ŒJSONé•¿åº¦ {section_length} å­—èŠ‚")
        
        if not send_combined_message(section_title, section):
            success = False
    
    return success

def get_book_titles(page_num):
    """è·å–æŒ‡å®šé¡µçš„ä¹¦ç±æ ‡é¢˜å’Œå‡ºç‰ˆæ—¶é—´"""
    url = f"https://www.tongli.com.tw/Search1.aspx?Page={page_num}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        logging.info(f"å¼€å§‹çˆ¬å–ç¬¬{page_num}é¡µ: {url}")
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æå–å‡ºä¹¦è¡¨æœˆä»½
        month_element = soup.select_one('h5.sdBook_t span#ContentPlaceHolder1_DataMonth')
        publish_month = month_element.get_text(strip=True) if month_element else "æœªçŸ¥æœˆä»½"
        logging.info(f"å½“å‰çˆ¬å–çš„æ˜¯ {publish_month} çš„å‡ºä¹¦è¡¨")
        
        book_elements = soup.select('td[data-th="æ›¸åï¼é›†æ•¸"]')
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logging.info(f"é¡µé¢çŠ¶æ€ç : {response.status_code}")
        logging.info(f"æå–åˆ° {len(book_elements)} æœ¬ä¹¦ç±æ ‡é¢˜")
        
        # è¾“å‡ºå‰3ä¸ªæ ‡é¢˜ï¼ˆè°ƒè¯•ç”¨ï¼‰
        if book_elements:
            sample_titles = [element.get_text(strip=True) for element in book_elements[:3]]
            logging.info(f"ç¤ºä¾‹æ ‡é¢˜: {sample_titles}")
        
        # å¤„ç†ä¹¦åï¼Œç§»é™¤å¯èƒ½çš„è¡Œå·å‰ç¼€
        processed_titles = []
        for title in [element.get_text(strip=True) for element in book_elements]:
            # ç§»é™¤å¯èƒ½çš„è¡Œå·å‰ç¼€ï¼ˆå¦‚"1."ã€"1ã€"ç­‰ï¼‰
            processed_title = title.lstrip('0123456789.ã€ ')
            processed_titles.append(processed_title)
        
        return {
            "publish_month": publish_month,
            "titles": processed_titles
        }
    except Exception as e:
        logging.error(f"çˆ¬å–ç¬¬{page_num}é¡µæ—¶å‡ºé”™: {str(e)}")
        return {
            "publish_month": "æœªçŸ¥æœˆä»½",
            "titles": []
        }

def main():
    """ä¸»å‡½æ•°ï¼ˆç›´æ¥æ‰§è¡Œï¼Œæ— éœ€äº‘å‡½æ•°å…¥å£ï¼‰"""
    try:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        new_books = []  # å­˜å‚¨æ–°å‘ç°çš„ä¹¦ç±
        published_books = []  # å­˜å‚¨å·²å‡ºä¹¦çš„ä¹¦ç±
        publish_months = set()
        
        # è®°å½•æ‰§è¡Œæ—¶é—´ï¼ˆè½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ UTC+8ï¼‰
        utc_time = datetime.datetime.utcnow()
        beijing_time = utc_time + datetime.timedelta(hours=8)
        execute_time = beijing_time.strftime("%Y-%m-%d %H:%M:%S")
        today = beijing_time.strftime("%Y-%m-%d")
        logging.info(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œæ—¶é—´: {execute_time} (åŒ—äº¬æ—¶é—´)")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        create_database()
        
        # çˆ¬å–ä¸‰é¡µæ•°æ®
        current_books = []
        for page in range(1, 4):
            result = get_book_titles(page)
            titles = result["titles"]
            publish_month = result["publish_month"]
            publish_months.add(publish_month)
            
            logging.info(f"ç¬¬{page}é¡µè·å–åˆ°{len(titles)}æœ¬ä¹¦ç±æ ‡é¢˜ ({publish_month})")
            
            # è®°å½•æ‰€æœ‰ä¹¦ç±
            for title in titles:
                book_info = {
                    "title": title,
                    "publish_month": publish_month
                }
                current_books.append(book_info)
                
                # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ— è®ºæ˜¯å¦å·²å‡ºç‰ˆï¼‰
                if not check_book_exists(title):
                    # æ–°ä¹¦ï¼šæ·»åŠ åˆ°æ•°æ®åº“å¹¶è®°å½•
                    if add_book(title, publish_month, today, today):
                        new_books.append({
                            "title": title,
                            "publish_month": publish_month,
                            "first_seen": today
                        })
                        logging.info(f"å‘ç°æ–°ä¹¦: {title} (å‡ºç‰ˆæœˆä»½: {publish_month})")
                else:
                    # å·²å­˜åœ¨çš„ä¹¦ç±ï¼šæ›´æ–°last_seen
                    update_book_last_seen(title, today)
                    logging.info(f"å·²å­˜åœ¨çš„ä¹¦ç±: {title}")
        
        # ç”Ÿæˆæœˆä»½èŒƒå›´
        month_range = "ã€".join(sorted(publish_months)) if publish_months else "æœªçŸ¥æœˆä»½"
        
        # æ¯å¤©æ£€æŸ¥å¹¶æ ‡è®°å·²å‡ºä¹¦çš„ä¹¦ç±
        logging.info("æ‰§è¡Œæ¯æ—¥å·²å‡ºä¹¦ä¹¦ç±æ£€æŸ¥")
        published_books = check_and_mark_published_books(current_books)
        logging.info(f"å…±å‘ç°{len(published_books)}æœ¬å·²å‡ºä¹¦çš„ä¹¦ç±")
        
        # å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥
        notification_content = ""
        
        # æ·»åŠ æ–°ä¹¦ä¿¡æ¯
        if new_books:
            total_new_books = len(new_books)
            notification_content += f"ğŸ‰ **ä»Šæ—¥å‘ç° {total_new_books} æœ¬é¢„å®šå‡ºä¹¦** ğŸ‰\n\n"
            
            # æŒ‰æœˆä»½åˆ†ç»„
            books_by_month = {}
            for book in new_books:
                month = book['publish_month']
                if month not in books_by_month:
                    books_by_month[month] = []
                books_by_month[month].append(book)
            
            # æŒ‰æœˆä»½ç”Ÿæˆå†…å®¹
            for month, books in books_by_month.items():
                notification_content += f"## ğŸ“… {month} é¢„å®šå‡ºç‰ˆçš„æ–°ä¹¦\n\n"
                for i, book in enumerate(books, 1):
                    notification_content += f"### {i}. {book['title']}\n"
                    notification_content += f"- é¦–æ¬¡å‘ç°: `{book['first_seen']}`\n\n"
        
        # æ·»åŠ å·²å‡ºä¹¦ä¿¡æ¯
        if published_books:
            total_published_books = len(published_books)
            notification_content += f"ğŸ“¦ **ä»Šæ—¥æœ‰ {total_published_books} æœ¬ä¹¦å·²å‡ºç‰ˆ** ğŸ“¦\n\n"
            
            # æŒ‰æœˆä»½åˆ†ç»„
            published_by_month = {}
            for book in published_books:
                month = book['publish_month']
                if month not in published_by_month:
                    published_by_month[month] = []
                published_by_month[month].append(book)
            
            # æŒ‰æœˆä»½ç”Ÿæˆå†…å®¹
            for month, books in published_by_month.items():
                notification_content += f"## ğŸ“… {month} å·²å‡ºç‰ˆçš„ä¹¦ç±\n\n"
                for i, book in enumerate(books, 1):
                    notification_content += f"### {i}. {book['title']}\n"
                    notification_content += f"- é¦–æ¬¡å‡ºç°: `{book['first_seen']}`\n"
                    notification_content += f"- æœ€åå‡ºç°: `{book['last_seen']}`\n"
                    notification_content += f"- çŠ¶æ€: âœ… **å·²å‡ºç‰ˆ**\n\n"
        
        # å¦‚æœæœ‰æ–°ä¹¦æˆ–å·²å‡ºä¹¦ï¼Œå‘é€ç»¼åˆé€šçŸ¥
        if new_books or published_books:
            notification_title = f"ğŸ“š {execute_time} ä¹¦ç±æ›´æ–° ({month_range})"
            
            # å‘é€åˆå¹¶åçš„é€šçŸ¥ï¼ˆè€ƒè™‘APIé™åˆ¶ï¼‰
            if send_wechat_notification(notification_title, notification_content):
                logging.info(f"æˆåŠŸæ¨é€åˆå¹¶åçš„æ›´æ–°é€šçŸ¥: {len(new_books)}æœ¬é¢„å®šå‡ºä¹¦, {len(published_books)}æœ¬å·²å‡ºä¹¦")
            else:
                logging.error("æ¨é€åˆå¹¶åçš„æ›´æ–°é€šçŸ¥å¤±è´¥")
        else:
            # æ²¡æœ‰æ–°ä¹¦å’Œå·²å‡ºä¹¦
            content = f"ä»Šæ—¥æ²¡æœ‰å‘ç°æ–°çš„é¢„å®šå‡ºä¹¦ï¼Œä¹Ÿæ²¡æœ‰ä¹¦ç±æ ‡è®°ä¸ºå·²å‡ºç‰ˆã€‚\n\n"
            content += f"ğŸ“… å½“å‰æŸ¥è¯¢æœˆä»½: {month_range}\n"
            content += f"ğŸ•’ æ£€æµ‹æ—¶é—´: {execute_time}\n"
            send_wechat_notification(f"ğŸ“š {execute_time} æ— æ›´æ–° ({month_range})", content)
            logging.info("ä»Šæ—¥æ— æ›´æ–°")
                
    except Exception as e:
        logging.error(f"æ‰§è¡Œçˆ¬è™«æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        error_content = f"é”™è¯¯ä¿¡æ¯: `{str(e)}`\n\n"
        error_content += f"ğŸ•’ é”™è¯¯æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        send_wechat_notification(f"âŒ {execute_time} çˆ¬è™«æ‰§è¡Œå¤±è´¥", error_content)
        raise  # è®©GitHub Actionsæ ‡è®°ä»»åŠ¡å¤±è´¥

if __name__ == "__main__":
    main()
